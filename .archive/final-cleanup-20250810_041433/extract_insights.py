#!/usr/bin/env python3
"""
488ê°œ ë¬¸ì„œì—ì„œ í•µì‹¬ ì¸ì‚¬ì´íŠ¸ ì¶”ì¶œ
"""

import os
import re
from collections import defaultdict
from datetime import datetime

class InsightExtractor:
    def __init__(self):
        self.insights = {
            'errors_solved': [],      # í•´ê²°í•œ ì—ëŸ¬ë“¤
            'patterns_found': [],      # ë°œê²¬í•œ íŒ¨í„´ë“¤
            'principles': [],          # í•µì‹¬ ì›ì¹™ë“¤
            'lessons_learned': [],     # ë°°ìš´ êµí›ˆë“¤
            'best_practices': [],      # ëª¨ë²” ì‚¬ë¡€ë“¤
            'anti_patterns': [],       # í”¼í•´ì•¼ í•  íŒ¨í„´
            'tools_created': [],       # ë§Œë“  ë„êµ¬ë“¤
            'workflows': [],           # ì›Œí¬í”Œë¡œìš° ê°œì„ 
        }
        
        # í‚¤ì›Œë“œ ë§¤í•‘
        self.keywords = {
            'errors_solved': ['í•´ê²°', 'fixed', 'solution', 'error', 'bug', 'ì˜¤ë¥˜'],
            'patterns_found': ['íŒ¨í„´', 'pattern', 'discovered', 'ë°œê²¬'],
            'principles': ['ì›ì¹™', 'principle', 'rule', 'must', 'í•„ìˆ˜'],
            'lessons_learned': ['ë°°ìš´', 'learned', 'lesson', 'êµí›ˆ', 'ê¹¨ë‹¬ìŒ'],
            'best_practices': ['best', 'practice', 'ëª¨ë²”', 'ì¶”ì²œ', 'recommend'],
            'anti_patterns': ['avoid', 'don\'t', 'ê¸ˆì§€', 'í•˜ì§€ë§ˆ', 'antipattern'],
            'tools_created': ['tool', 'script', 'ë„êµ¬', 'ìŠ¤í¬ë¦½íŠ¸', 'automation'],
            'workflows': ['workflow', 'process', 'í”„ë¡œì„¸ìŠ¤', 'ë‹¨ê³„', 'step']
        }
        
    def extract_from_file(self, filepath):
        """íŒŒì¼ì—ì„œ ì¸ì‚¬ì´íŠ¸ ì¶”ì¶œ"""
        try:
            with open(filepath, 'r', encoding='utf-8') as f:
                content = f.read()
                
            # ë¹ˆ íŒŒì¼ ê±´ë„ˆë›°ê¸°
            if not content.strip() or len(content) < 100:
                return
                
            # ê° ì¹´í…Œê³ ë¦¬ë³„ë¡œ ì¸ì‚¬ì´íŠ¸ ì¶”ì¶œ
            for category, keywords in self.keywords.items():
                for keyword in keywords:
                    if keyword.lower() in content.lower():
                        # í‚¤ì›Œë“œ ì£¼ë³€ ë¬¸ë§¥ ì¶”ì¶œ
                        insights = self.extract_context(content, keyword, filepath)
                        if insights:
                            self.insights[category].extend(insights)
                        break  # ì¹´í…Œê³ ë¦¬ë‹¹ í•œ ë²ˆë§Œ
                        
        except Exception as e:
            pass
            
    def extract_context(self, content, keyword, filepath):
        """í‚¤ì›Œë“œ ì£¼ë³€ì˜ ì˜ë¯¸ ìˆëŠ” ë¬¸ë§¥ ì¶”ì¶œ"""
        insights = []
        lines = content.split('\n')
        
        for i, line in enumerate(lines):
            if keyword.lower() in line.lower():
                # ì œëª©ì´ë‚˜ ì¤‘ìš”í•œ ë¬¸ì¥ ì¶”ì¶œ
                if line.startswith('#') or line.startswith('-') or ':' in line:
                    insight = {
                        'text': line.strip(),
                        'file': os.path.relpath(filepath),
                        'context': self.get_surrounding_context(lines, i)
                    }
                    
                    # ì¤‘ë³µ ì œê±° (ìœ ì‚¬í•œ í…ìŠ¤íŠ¸)
                    if not self.is_duplicate(insight['text'], insights):
                        insights.append(insight)
                        
        return insights[:3]  # íŒŒì¼ë‹¹ ìµœëŒ€ 3ê°œ
        
    def get_surrounding_context(self, lines, index):
        """ì£¼ë³€ 2ì¤„ì˜ ì»¨í…ìŠ¤íŠ¸ ê°€ì ¸ì˜¤ê¸°"""
        start = max(0, index - 1)
        end = min(len(lines), index + 2)
        return '\n'.join(lines[start:end])
        
    def is_duplicate(self, text, insights_list):
        """ì¤‘ë³µ ì²´í¬"""
        text_lower = text.lower().strip()
        for insight in insights_list:
            if isinstance(insight, dict):
                if text_lower in insight.get('text', '').lower():
                    return True
            elif text_lower in str(insight).lower():
                return True
        return False
        
    def scan_all_files(self):
        """ëª¨ë“  ë§ˆí¬ë‹¤ìš´ íŒŒì¼ ìŠ¤ìº”"""
        exclude_dirs = {'.git', '.backup', '.archive', 'node_modules'}
        
        file_count = 0
        for root, dirs, files in os.walk('.'):
            dirs[:] = [d for d in dirs if d not in exclude_dirs]
            
            for file in files:
                if file.endswith('.md'):
                    filepath = os.path.join(root, file)
                    self.extract_from_file(filepath)
                    file_count += 1
                    
        print(f"âœ“ {file_count}ê°œ íŒŒì¼ ìŠ¤ìº” ì™„ë£Œ")
        
    def deduplicate_insights(self):
        """ì¸ì‚¬ì´íŠ¸ ì¤‘ë³µ ì œê±° ë° ì •ë¦¬"""
        for category in self.insights:
            # í…ìŠ¤íŠ¸ë§Œ ì¶”ì¶œí•˜ì—¬ ì¤‘ë³µ ì œê±°
            unique_texts = []
            seen = set()
            
            for item in self.insights[category]:
                if isinstance(item, dict):
                    text = item.get('text', '')
                else:
                    text = str(item)
                    
                # ì •ê·œí™”
                normalized = re.sub(r'[^a-zA-Z0-9ê°€-í£]', '', text.lower())
                
                if normalized and normalized not in seen:
                    seen.add(normalized)
                    unique_texts.append({
                        'text': text,
                        'file': item.get('file', '') if isinstance(item, dict) else ''
                    })
                    
            self.insights[category] = unique_texts[:20]  # ì¹´í…Œê³ ë¦¬ë‹¹ ìµœëŒ€ 20ê°œ
            
    def generate_summary(self):
        """ì¸ì‚¬ì´íŠ¸ ìš”ì•½ ìƒì„±"""
        summary = []
        summary.append("# ğŸ” ì¶”ì¶œëœ í•µì‹¬ ì¸ì‚¬ì´íŠ¸\n")
        summary.append(f"ìƒì„± ì‹œê°: {datetime.now().isoformat()}\n")
        
        # í†µê³„
        total = sum(len(items) for items in self.insights.values())
        summary.append(f"## ğŸ“Š í†µê³„")
        summary.append(f"- ì´ ì¸ì‚¬ì´íŠ¸: {total}ê°œ")
        summary.append(f"- ì¹´í…Œê³ ë¦¬: {len(self.insights)}ê°œ\n")
        
        # ì¹´í…Œê³ ë¦¬ë³„ ì¸ì‚¬ì´íŠ¸
        category_names = {
            'errors_solved': 'ğŸ”§ í•´ê²°í•œ ë¬¸ì œë“¤',
            'patterns_found': 'ğŸ” ë°œê²¬í•œ íŒ¨í„´ë“¤',
            'principles': 'ğŸ“ í•µì‹¬ ì›ì¹™ë“¤',
            'lessons_learned': 'ğŸ’¡ ë°°ìš´ êµí›ˆë“¤',
            'best_practices': 'âœ… ëª¨ë²” ì‚¬ë¡€ë“¤',
            'anti_patterns': 'âŒ í”¼í•´ì•¼ í•  ê²ƒë“¤',
            'tools_created': 'ğŸ› ï¸ ë§Œë“  ë„êµ¬ë“¤',
            'workflows': 'ğŸ”„ ì›Œí¬í”Œë¡œìš°'
        }
        
        for category, items in self.insights.items():
            if items:
                summary.append(f"\n## {category_names.get(category, category)}")
                summary.append(f"*{len(items)}ê°œ ë°œê²¬*\n")
                
                for i, item in enumerate(items[:10], 1):  # ìƒìœ„ 10ê°œë§Œ
                    if isinstance(item, dict):
                        text = item.get('text', '').strip()
                        file = item.get('file', '')
                        if text:
                            # ë§ˆí¬ë‹¤ìš´ í—¤ë” ì œê±°
                            text = re.sub(r'^#+\s*', '', text)
                            summary.append(f"{i}. {text}")
                            if file:
                                summary.append(f"   *(from: {file})*")
                    else:
                        summary.append(f"{i}. {item}")
                        
        return '\n'.join(summary)
        
    def save_insights(self):
        """ì¸ì‚¬ì´íŠ¸ë¥¼ íŒŒì¼ë¡œ ì €ì¥"""
        # 1. ì „ì²´ ìš”ì•½
        with open('EXTRACTED_INSIGHTS.md', 'w', encoding='utf-8') as f:
            f.write(self.generate_summary())
            
        # 2. 10ê°œ í•µì‹¬ íŒŒì¼ì— í†µí•©í•  ë‚´ìš©
        self.create_consolidated_files()
        
        print("âœ“ ì¸ì‚¬ì´íŠ¸ ì¶”ì¶œ ì™„ë£Œ: EXTRACTED_INSIGHTS.md")
        
    def create_consolidated_files(self):
        """í•µì‹¬ íŒŒì¼ì— í†µí•©í•  ë‚´ìš© ìƒì„±"""
        
        # LESSONS.md - ëª¨ë“  êµí›ˆ í†µí•©
        lessons_content = "# ğŸ“š ì¶•ì ëœ ì§€ì‹\n\n"
        lessons_content += "## í•´ê²°í•œ ë¬¸ì œë“¤\n"
        for item in self.insights['errors_solved'][:10]:
            if isinstance(item, dict):
                lessons_content += f"- {item.get('text', '')}\n"
                
        lessons_content += "\n## ë°œê²¬í•œ íŒ¨í„´ë“¤\n"
        for item in self.insights['patterns_found'][:10]:
            if isinstance(item, dict):
                lessons_content += f"- {item.get('text', '')}\n"
                
        with open('LESSONS.md', 'w', encoding='utf-8') as f:
            f.write(lessons_content)
            
        # PRINCIPLES_CONSOLIDATED.md - ëª¨ë“  ì›ì¹™ í†µí•©
        principles_content = "# ğŸ¯ í†µí•© ì›ì¹™\n\n"
        for item in self.insights['principles'][:15]:
            if isinstance(item, dict):
                principles_content += f"- {item.get('text', '')}\n"
                
        with open('PRINCIPLES_CONSOLIDATED.md', 'w', encoding='utf-8') as f:
            f.write(principles_content)
            
        print("âœ“ í†µí•© íŒŒì¼ ìƒì„±: LESSONS.md, PRINCIPLES_CONSOLIDATED.md")

if __name__ == '__main__':
    extractor = InsightExtractor()
    print("ğŸ“Š ì¸ì‚¬ì´íŠ¸ ì¶”ì¶œ ì‹œì‘...")
    extractor.scan_all_files()
    extractor.deduplicate_insights()
    extractor.save_insights()
    print("âœ… ì™„ë£Œ!")